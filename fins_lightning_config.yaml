sample_rate: 44100 # note: any loaded IR and speech data will be resampled to this rate
datasets_path: ./Datasets 
base_speech_dataset: "HiFi" # options: "LibriSpeech", "HiFi". 
rir_datasets: ["homula", "MIT"] # options: homula, MIT, sim
# preencoded_speech: True # tells dataloader not to encode on the fly, as audio being loaded is already encoded
speech_datasets: ["preencoded_test5"] # relative to datasets_path. If the name of directory in datasets_path, will be treated as a dataset path
random_seed: 42
nwins: 32 # the model input size = nwins * win_size. Note: original FINS uses 131072 samples of input at 48 kHz
min_early_reverb: 0.0  # minimum permitted early reverb time for considered RIRs(seconds). The early reverb is taken to be the time where the RIR is at its maximum value.
align_ir: True # whether to align the IR so the direct path is at the start of the IR. 
plot_every_n_steps: 250
data_in_ram: False

Encoding: # echo encoding params
  # note: the below delays have been adapted to the 48kHz sampling rate, as opposed to the previously used 16khz
  delays: [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]
  amplitude: 0.4
  win_size: 3072
  kernel: "bp"
  decoding: "cepstrum" # options: "autocepstrum", "cepstrum"
  cutoff_freq: 1000
  hanning_factor: 4

fins:
  rir_duration: 1.0
  direct_delay : 100
  peak_norm_value : 0.5
  source_norm_value : -25.0
  num_filters : 10
  filter_order : 1023
  early_length : 2400
  decoder_input_length : 368 # 400 is used by original FINS (assumes 48kz data)
  noise_condition_length : 16
  z_size : 128
  min_snr : 15
  max_snr : 50
  normalize : "rms"
  rms_level : 0.01 
  gradient_clip_value : 5
  lr: 0.000055
  lr_step_size : 80
  lr_decay_factor : 0.8

dare:
  learning_rate: 0.0001 
  use_transformer: True
  alphas: [2000, 0.5, 10, 0] # cepstrum MSE loss weight, symbol error rate weight, full cepstrum MES loss weight, average error reduction loss weight
  softargmax_beta : 10000000
  residual: True
  norm_cepstra: False
  cep_target_region: [40, 125] # start and end (samples) of region of the cepstrum to consider in computing the cepstrum loss # NOTE: Should be related to delays below

joint:
  lr: 0.0001
  alphas: [2000, 0.5, 10, 0] # cepstrum MSE loss weight, symbol error rate weight, RIR STFT loss, RIR similarity
  # 1e-4, 1, >1, 1e-6
  
DataLoader:
  batch_size: 8
  num_workers: 32
  persistent_workers: True
  shuffle: True
  drop_last: True
  pin_memory: True

Trainer:
  limit_train_batches: 10000
  limit_val_batches: 100
  limit_test_batches: 100
  max_epochs: 100
  num_sanity_val_steps: 1
  accumulate_grad_batches: 1
  log_every_n_steps: 10 # logs every n steps where n iss the number of batches
  val_check_interval: 0.1 # val every this fraction of an epoch
  # check_val_every_n_epoch: 1
  accelerator: gpu
  devices: [1]

ModelCheckpoint:
  dirpath: fins_checkpoints
  every_n_train_steps: 1000

AdvancedProfiler:
  dirpath: null
  filename: advanced_profiler.txt
  line_count_restriction: 1.0

LearningRateMonitor:
  logging_interval: epoch

DDPStrategy:
  process_group_backend: gloo
  find_unused_parameters: False