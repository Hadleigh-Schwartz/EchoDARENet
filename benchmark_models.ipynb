{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de95d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import torch as t\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from utils.utils import load_config\n",
    "from models.cep3_model import Test\n",
    "from models.joint_model import JointModel\n",
    "from fins_lightning_dataloader import DareDataModule\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "echo_dir = curr_dir.split(\"EchoDARENet\")[0] \n",
    "sys.path.append(echo_dir)\n",
    "from traditional_echo_hiding import encode, decode, get_autocepstrum, get_cepstrum, butter_highpass_filter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3349436",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"fins_lightning_config.yaml\"\n",
    "cfg = load_config(config_path)\n",
    "\n",
    "# unet_model = Test(learning_rate = cfg.dare.learning_rate,\n",
    "#                 nwins = cfg.nwins,\n",
    "#                 use_transformer = cfg.dare.use_transformer,\n",
    "#                 alphas = cfg.dare.alphas,\n",
    "#                 softargmax_beta = cfg.dare.softargmax_beta,\n",
    "#                 residual=cfg.dare.residual,\n",
    "#                 delays = cfg.Encoding.delays,\n",
    "#                 win_size = cfg.Encoding.win_size,\n",
    "#                 cutoff_freq = cfg.Encoding.cutoff_freq,\n",
    "#                 sample_rate = cfg.sample_rate,\n",
    "#                 plot_every_n_steps=cfg.plot_every_n_steps,\n",
    "#                 norm_cepstra = cfg.dare.norm_cepstra,\n",
    "#                 cepstrum_target_region = cfg.dare.cep_target_region)\n",
    "\n",
    "# # load checkpoint\n",
    "# unet_checkpoint_path = \"EchoDARENet/lightning_logs/cepstrum/epoch=00-val_loss=0.20.ckpt\"\n",
    "# unet_checkpoint = t.load(unet_checkpoint_path, map_location=t.device('cpu'))\n",
    "# unet_model.load_state_dict(unet_checkpoint['state_dict'])\n",
    "# unet_model.eval()\n",
    "\n",
    "\n",
    "# joint_model = JointModel(cfg)\n",
    "\n",
    "# joint_model_checkpoint_path = \"EchoDARENet/lightning_logs/joint/epoch=00-val_loss=0.20.ckpt\"\n",
    "# joint_model_checkpoint = t.load(joint_model_checkpoint_path, map_location=t.device('cpu'))\n",
    "# joint_model.load_state_dict(joint_model_checkpoint['state_dict'])\n",
    "# joint_model.eval()\n",
    "\n",
    "# set up encoding params\n",
    "delays = cfg.Encoding.delays\n",
    "amplitude = cfg.Encoding.amplitude\n",
    "win_size = cfg.Encoding.win_size\n",
    "cutoff_freq = cfg.Encoding.cutoff_freq\n",
    "kernel = cfg\n",
    "pn = None\n",
    "np.random.seed(0)\n",
    "\n",
    "datamodule = DareDataModule(config=cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b5ae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1536, 32])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n",
      "torch.Size([1536])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 32 is out of bounds for dimension 2 with size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d453e0a96d6c>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcepstra_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_wins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mwindow_cepstrum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcepstra_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_cepstrum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mcompute_symbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_cepstrum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 32 is out of bounds for dimension 2 with size 32"
     ]
    }
   ],
   "source": [
    "# for i in range(cepstra_clean.shape[-1]):\n",
    "#         pred_symbol = compute_symbol(cepstra_clean[0, :, i], delays)\n",
    "\n",
    "\n",
    "def compute_symbol(cepstrum, delays):\n",
    "    cep_vals = cepstrum[delays]\n",
    "    max_val = np.argmax(cep_vals)\n",
    "    return max_val\n",
    "\n",
    "# get test data from datamodule (makes sure we are using new IRs, speech from training)\n",
    "test_dataloader = datamodule.test_dataloader()\n",
    "# iterate through the test dataloader\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    # get the data\n",
    "    enc_speech_cepstra, enc_reverb_speech_cepstra, unenc_reverb_speech_cepstra, \\\n",
    "                enc_speech_wav, enc_reverb_speech_wav, unenc_reverb_speech_wav, \\\n",
    "                rir, stochastic_noise, noise_condition, symbols,  idx_rir, num_errs_no_reverb, num_errs_reverb = batch\n",
    "    num_wins = enc_speech_cepstra.shape[2]\n",
    "    for cepstra_set in enc_reverb_speech_cepstra:\n",
    "        print(cepstra_set.shape)\n",
    "        for i in range(num_wins):\n",
    "            window_cepstrum = cepstra_set[0, :, i]\n",
    "            print(window_cepstrum.shape)\n",
    "            compute_symbol(window_cepstrum, delays)\n",
    "        \n",
    "    # decode cepstra as-is\n",
    "\n",
    "    # forward pass through model 1\n",
    "    # decode cepstra and compute errors\n",
    "    # forward pass through model 2\n",
    "    # decode cepstra and compute errors\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
